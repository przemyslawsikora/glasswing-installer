---
- name: Pull Spark image
  docker_image:
    name: gettyimages/spark
    tag: latest

- name: Create Spark master conf volume
  docker_volume:
    name: spark-master-conf

- name: Create Spark worker conf volume
  docker_volume:
    name: spark-worker-conf

- name: Create Spark data volume
  docker_volume:
    name: spark-data

- name: Create Spark master container
  docker_container:
    name: spark-master
    image: gettyimages/spark:latest
    network_mode: "{{ docker_network_name }}"
    networks:
      - name: "{{ docker_network_name }}"
        aliases:
          - sparkmaster
    hostname: sparkmaster
    restart_policy: always
    env:
      MASTER: spark://sparkmaster:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: localhost
    exposed_ports:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7077
      - 6066
    published_ports:
#      - 4040:4040
#      - 6066:6066
#      - 7077:7077
      - 127.0.0.1:8080:8080
    volumes:
      - spark-master-conf:/conf
      - spark-data:/tmp/data
    command: bin/spark-class org.apache.spark.deploy.master.Master -h sparkmaster

- name: Create Spark worker container
  docker_container:
    name: spark-worker
    image: gettyimages/spark:latest
    network_mode: "{{ docker_network_name }}"
    networks:
      - name: "{{ docker_network_name }}"
        aliases:
          - sparkworker
    hostname: sparkworker
    restart_policy: always
    env:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
    exposed_ports:
      - 7012
      - 7013
      - 7014
      - 7015
      - 8881
    published_ports:
      - 127.0.0.1:8081:8081
    volumes:
      - spark-worker-conf:/conf
      - spark-data:/tmp/data
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://sparkmaster:7077
